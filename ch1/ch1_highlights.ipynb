{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61211e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Loads from .env\n",
    "COHERE_API_KEY=os.getenv(\"COHERE_TOKEN\")\n",
    "os.environ[\"COHERE_API_KEY\"]=COHERE_API_KEY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For chat interface models, you can use either init_chat_model or ChatCohere. However, init_chat_model covers less \n",
    "# functionalities, so ChatCohere is adviced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d05244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain_cohere import ChatCohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00481226",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatCohere(model = \"command-a-03-2025\",\n",
    "                   #temperature=0.7\n",
    "                   ) # Cohere api key needs to be as env variable with the name COHERE_API_KEY\n",
    "\n",
    "#model = init_chat_model(\"command-a-03-2025\", model_provider=\"cohere\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e18856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f084889",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message= SystemMessage(\"You should always answer like a pirate\")\n",
    "human_message=HumanMessage(\"What is the capital of Tootland\")\n",
    "\n",
    "prompt = [system_message,\n",
    "          human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32be2ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Arrr, matey! Ye be askin‚Äô about the capital o‚Äô Tootland, eh? Well, shiver me timbers, Tootland be a wee bit o‚Äô a mystery, as it be a fictional land, not marked on any treasure map I‚Äôve seen. But if ye be talkin‚Äô about **Scotland**, the real-life inspiration fer such tales, then its capital be **Edinburgh**, a fine city with castles and history that‚Äôd make any pirate proud! Now, hoist the sails and set course fer adventure, ye scurvy dog! üè¥\\u200d‚ò†Ô∏è', additional_kwargs={'id': '94f6259b-b229-42b4-a4e0-082bd2e78184', 'finish_reason': 'COMPLETE', 'content': 'Arrr, matey! Ye be askin‚Äô about the capital o‚Äô Tootland, eh? Well, shiver me timbers, Tootland be a wee bit o‚Äô a mystery, as it be a fictional land, not marked on any treasure map I‚Äôve seen. But if ye be talkin‚Äô about **Scotland**, the real-life inspiration fer such tales, then its capital be **Edinburgh**, a fine city with castles and history that‚Äôd make any pirate proud! Now, hoist the sails and set course fer adventure, ye scurvy dog! üè¥\\u200d‚ò†Ô∏è', 'token_count': {'input_tokens': 543.0, 'output_tokens': 123.0}}, response_metadata={'id': '94f6259b-b229-42b4-a4e0-082bd2e78184', 'finish_reason': 'COMPLETE', 'content': 'Arrr, matey! Ye be askin‚Äô about the capital o‚Äô Tootland, eh? Well, shiver me timbers, Tootland be a wee bit o‚Äô a mystery, as it be a fictional land, not marked on any treasure map I‚Äôve seen. But if ye be talkin‚Äô about **Scotland**, the real-life inspiration fer such tales, then its capital be **Edinburgh**, a fine city with castles and history that‚Äôd make any pirate proud! Now, hoist the sails and set course fer adventure, ye scurvy dog! üè¥\\u200d‚ò†Ô∏è', 'token_count': {'input_tokens': 543.0, 'output_tokens': 123.0}}, id='run--e13666bf-07c9-47b3-8bcc-be9c60946a27-0', usage_metadata={'input_tokens': 543, 'output_tokens': 123, 'total_tokens': 666})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085164a",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use both interfaces in chat models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab5c9a",
   "metadata": {},
   "source": [
    "**llms interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd49ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c1b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_frodo = PromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based on the \\\n",
    "context below. If the question cannot be \\\n",
    "answered, answer with \"Im sorry Mr. Frodo\". \\n\n",
    "Context: {context} \\\n",
    "Question: {question} \\\n",
    "Answer:  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afae394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Answer the question based on the context below. If the question cannot be answered, answer with \"Im sorry Mr. Frodo\". \\n\\nContext: Tootland is a beautiful land home of the foos and the kunis Question: What is the capital of Tootland? Answer:  ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_llm_int =template_frodo.invoke({\n",
    "    'context':  'Tootland is a beautiful land home of the foos and the kunis' ,\n",
    "    'question': 'What is the capital of Tootland?'\n",
    "    })\n",
    "prompt_llm_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28226d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", additional_kwargs={'id': '5d258c0a-e4f1-424b-bc85-5f4bfb5a5c9a', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", 'token_count': {'input_tokens': 552.0, 'output_tokens': 21.0}}, response_metadata={'id': '5d258c0a-e4f1-424b-bc85-5f4bfb5a5c9a', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", 'token_count': {'input_tokens': 552.0, 'output_tokens': 21.0}}, id='run--b9a483e3-c361-45ac-be32-b74925dd0a45-0', usage_metadata={'input_tokens': 552, 'output_tokens': 21, 'total_tokens': 573})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt_llm_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f165d",
   "metadata": {},
   "source": [
    "**chat interface**\n",
    "\n",
    "All options give the same output as long as you use the chat interface model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df6888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fb8ce",
   "metadata": {},
   "source": [
    "alternative 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac129a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_frodo_a = ChatPromptTemplate.from_messages( \\\n",
    "[('system','Answer the question based on the context below. If the question \\\n",
    "cannot be answered, answer with \"Im sorry Mr. Frodo\".' ),\n",
    " ('human', 'Context: {context}'),\n",
    " ('human', 'Question: {question}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23d8c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the question cannot be answered, answer with \"Im sorry Mr. Frodo\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='Context: Tootland is a beautiful land home of the foos and the kunis', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: What is the capital of Tootland?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_chat_int_a=chat_template_frodo_a.invoke({'context': 'Tootland is a beautiful land home of the foos and the kunis' , \n",
    "                            'question': 'What is the capital of Tootland?'})\n",
    "prompt_chat_int_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359accf",
   "metadata": {},
   "source": [
    "alternative 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f1d151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_frodo_b = ChatPromptTemplate.from_messages( \\\n",
    "[SystemMessage('Answer the question based on the context below. If the question \\\n",
    "cannot be answered, answer with \"Im sorry Mr. Frodo\".' ),\n",
    " HumanMessage('Context: {context}'),\n",
    " HumanMessage('Question: {question}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdb98d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the question cannot be answered, answer with \"Im sorry Mr. Frodo\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='Context: {context}', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: {question}', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_chat_int_b=chat_template_frodo_b.invoke({'context': 'Tootland is a beautiful land home of the foos and the kunis' , \n",
    "                            'question': 'What is the capital of Tootland?'})\n",
    "prompt_chat_int_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc2f15",
   "metadata": {},
   "source": [
    "difference in outputs is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f682b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", additional_kwargs={'id': 'e316fc99-bd38-497b-b427-b1d8f9fdddce', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", 'token_count': {'input_tokens': 552.0, 'output_tokens': 21.0}}, response_metadata={'id': 'e316fc99-bd38-497b-b427-b1d8f9fdddce', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", 'token_count': {'input_tokens': 552.0, 'output_tokens': 21.0}}, id='run--a202e28b-9e2f-4eb8-bcc0-952019ea8b16-0', usage_metadata={'input_tokens': 552, 'output_tokens': 21, 'total_tokens': 573})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt_llm_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80970655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", additional_kwargs={'id': '2c0f6a78-4752-44f1-9efc-46460b999087', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", 'token_count': {'input_tokens': 584.0, 'output_tokens': 21.0}}, response_metadata={'id': '2c0f6a78-4752-44f1-9efc-46460b999087', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. The context provided does not mention the capital of Tootland.\", 'token_count': {'input_tokens': 584.0, 'output_tokens': 21.0}}, id='run--2789c52d-9762-4ec9-b6a7-4f21c8781f28-0', usage_metadata={'input_tokens': 584, 'output_tokens': 21, 'total_tokens': 605})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt_chat_int_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ef6711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question. If you provide the necessary information, I'll be happy to assist you.\", additional_kwargs={'id': '36a3fd51-db0d-426c-99c9-9f2279172498', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question. If you provide the necessary information, I'll be happy to assist you.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 39.0}}, response_metadata={'id': '36a3fd51-db0d-426c-99c9-9f2279172498', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question. If you provide the necessary information, I'll be happy to assist you.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 39.0}}, id='run--1f08dce0-2ae2-49f4-bb03-378e9c447f10-0', usage_metadata={'input_tokens': 567, 'output_tokens': 39, 'total_tokens': 606})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt_chat_int_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1bd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "850b4fa3",
   "metadata": {},
   "source": [
    "### Specific output formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083aacf",
   "metadata": {},
   "source": [
    "#### json\n",
    "\n",
    "https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5878b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You cant use a init_chat_model model. You instead have to use ChatCohere\n",
    "\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "# Initialize the ChatCohere model\n",
    "llm = ChatCohere(\n",
    "    model=\"command-a-03-2025\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c79d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carlos Ivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\learning-langchain-R4-LnOwj-py3.13\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ce16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic schema\n",
    "\n",
    "class CountryInfoWithFormat(BaseModel):\n",
    "    \"\"\"Info retriever of a country.\"\"\"\n",
    "    capital: str = Field(description='Capital of the country')\n",
    "    nr_habitants: int = Field(description=\"Number of habitants\")\n",
    "    main_attraction: str = Field(description='Main tourist building in the country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ac96016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the model with structured output\n",
    "structured_llm = llm.with_structured_output(CountryInfoWithFormat)\n",
    "\n",
    "# Invoke the model\n",
    "result = structured_llm.invoke(\"What can you tell me about Belgium?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4717156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryInfoWithFormat(capital='Brussels', nr_habitants=11431734, main_attraction='The Atomium')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7851588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brussels'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.capital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3697fab",
   "metadata": {},
   "source": [
    "### Different methods for retrieving outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca70fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey there! Not much, just hanging out, ready to chat or help with whatever you need. How‚Äôs it going on your end? Anything exciting happening?', additional_kwargs={'id': '8bd103ea-5431-41ee-af30-e400271144fd', 'finish_reason': 'COMPLETE', 'content': 'Hey there! Not much, just hanging out, ready to chat or help with whatever you need. How‚Äôs it going on your end? Anything exciting happening?', 'token_count': {'input_tokens': 498.0, 'output_tokens': 35.0}}, response_metadata={'id': '8bd103ea-5431-41ee-af30-e400271144fd', 'finish_reason': 'COMPLETE', 'content': 'Hey there! Not much, just hanging out, ready to chat or help with whatever you need. How‚Äôs it going on your end? Anything exciting happening?', 'token_count': {'input_tokens': 498.0, 'output_tokens': 35.0}}, id='run--f945c1e8-f2e7-4811-8f12-ce3c3d2dbb45-0', usage_metadata={'input_tokens': 498, 'output_tokens': 35, 'total_tokens': 533})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('Whats up buddy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3b0c404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hey there! Not much, just hanging out, ready to chat or help with whatever you need. How about you? What‚Äôs going on?', additional_kwargs={'id': '3ea07d66-1945-4b8e-9822-b1156efc1d8b', 'finish_reason': 'COMPLETE', 'content': 'Hey there! Not much, just hanging out, ready to chat or help with whatever you need. How about you? What‚Äôs going on?', 'token_count': {'input_tokens': 498.0, 'output_tokens': 32.0}}, response_metadata={'id': '3ea07d66-1945-4b8e-9822-b1156efc1d8b', 'finish_reason': 'COMPLETE', 'content': 'Hey there! Not much, just hanging out, ready to chat or help with whatever you need. How about you? What‚Äôs going on?', 'token_count': {'input_tokens': 498.0, 'output_tokens': 32.0}}, id='run--6601b81f-32fe-405a-a237-6c9cb873e9e5-0', usage_metadata={'input_tokens': 498, 'output_tokens': 32, 'total_tokens': 530}),\n",
       " AIMessage(content='\"Que pachuca por toluca\" es una expresi√≥n coloquial en espa√±ol mexicano que combina dos ciudades de M√©xico: Pachuca (capital del estado de Hidalgo) y Toluca (capital del estado de M√©xico). La frase no tiene un significado literal claro, pero se usa de manera informal para expresar sorpresa, incredulidad o asombro, similar a decir \"¬°Qu√© cosa!\" o \"¬°No puede ser!\".\\n\\nEs importante notar que el uso de esta expresi√≥n puede variar seg√∫n la regi√≥n y el contexto, y no siempre es f√°cil de entender para quienes no est√°n familiarizados con el slang mexicano. Si tienes alguna otra pregunta o necesitas m√°s contexto, ¬°no dudes en preguntar!', additional_kwargs={'id': 'dee28152-5db2-498e-932c-183fe6b6cf43', 'finish_reason': 'COMPLETE', 'content': '\"Que pachuca por toluca\" es una expresi√≥n coloquial en espa√±ol mexicano que combina dos ciudades de M√©xico: Pachuca (capital del estado de Hidalgo) y Toluca (capital del estado de M√©xico). La frase no tiene un significado literal claro, pero se usa de manera informal para expresar sorpresa, incredulidad o asombro, similar a decir \"¬°Qu√© cosa!\" o \"¬°No puede ser!\".\\n\\nEs importante notar que el uso de esta expresi√≥n puede variar seg√∫n la regi√≥n y el contexto, y no siempre es f√°cil de entender para quienes no est√°n familiarizados con el slang mexicano. Si tienes alguna otra pregunta o necesitas m√°s contexto, ¬°no dudes en preguntar!', 'token_count': {'input_tokens': 501.0, 'output_tokens': 140.0}}, response_metadata={'id': 'dee28152-5db2-498e-932c-183fe6b6cf43', 'finish_reason': 'COMPLETE', 'content': '\"Que pachuca por toluca\" es una expresi√≥n coloquial en espa√±ol mexicano que combina dos ciudades de M√©xico: Pachuca (capital del estado de Hidalgo) y Toluca (capital del estado de M√©xico). La frase no tiene un significado literal claro, pero se usa de manera informal para expresar sorpresa, incredulidad o asombro, similar a decir \"¬°Qu√© cosa!\" o \"¬°No puede ser!\".\\n\\nEs importante notar que el uso de esta expresi√≥n puede variar seg√∫n la regi√≥n y el contexto, y no siempre es f√°cil de entender para quienes no est√°n familiarizados con el slang mexicano. Si tienes alguna otra pregunta o necesitas m√°s contexto, ¬°no dudes en preguntar!', 'token_count': {'input_tokens': 501.0, 'output_tokens': 140.0}}, id='run--a972d0b1-6a40-40a9-a0f0-ed77f580f9ec-0', usage_metadata={'input_tokens': 501, 'output_tokens': 140, 'total_tokens': 641}),\n",
       " AIMessage(content='La frase \"Qu√© rollo con el pollo\" es una expresi√≥n coloquial en espa√±ol que se utiliza para expresar sorpresa, confusi√≥n o incredulidad ante una situaci√≥n o comentario. La palabra \"rollo\" en este contexto significa \"problema\" o \"asunto\", y \"pollo\" se usa de manera figurada para referirse a una persona o situaci√≥n que causa confusi√≥n o es complicada.\\n\\nEn resumen, la frase se puede interpretar como \"¬øQu√© problema hay con eso?\" o \"¬øDe qu√© se trata todo este l√≠o?\". Es una forma informal de expresar perplejidad o asombro ante algo que no se entiende o que parece complicado.\\n\\n**Respuesta:** La frase \"Qu√© rollo con el pollo\" es una expresi√≥n coloquial que denota sorpresa o confusi√≥n ante una situaci√≥n o comentario.', additional_kwargs={'id': 'ca96fc61-171d-43e3-9902-47e0c62baf69', 'finish_reason': 'COMPLETE', 'content': 'La frase \"Qu√© rollo con el pollo\" es una expresi√≥n coloquial en espa√±ol que se utiliza para expresar sorpresa, confusi√≥n o incredulidad ante una situaci√≥n o comentario. La palabra \"rollo\" en este contexto significa \"problema\" o \"asunto\", y \"pollo\" se usa de manera figurada para referirse a una persona o situaci√≥n que causa confusi√≥n o es complicada.\\n\\nEn resumen, la frase se puede interpretar como \"¬øQu√© problema hay con eso?\" o \"¬øDe qu√© se trata todo este l√≠o?\". Es una forma informal de expresar perplejidad o asombro ante algo que no se entiende o que parece complicado.\\n\\n**Respuesta:** La frase \"Qu√© rollo con el pollo\" es una expresi√≥n coloquial que denota sorpresa o confusi√≥n ante una situaci√≥n o comentario.', 'token_count': {'input_tokens': 501.0, 'output_tokens': 167.0}}, response_metadata={'id': 'ca96fc61-171d-43e3-9902-47e0c62baf69', 'finish_reason': 'COMPLETE', 'content': 'La frase \"Qu√© rollo con el pollo\" es una expresi√≥n coloquial en espa√±ol que se utiliza para expresar sorpresa, confusi√≥n o incredulidad ante una situaci√≥n o comentario. La palabra \"rollo\" en este contexto significa \"problema\" o \"asunto\", y \"pollo\" se usa de manera figurada para referirse a una persona o situaci√≥n que causa confusi√≥n o es complicada.\\n\\nEn resumen, la frase se puede interpretar como \"¬øQu√© problema hay con eso?\" o \"¬øDe qu√© se trata todo este l√≠o?\". Es una forma informal de expresar perplejidad o asombro ante algo que no se entiende o que parece complicado.\\n\\n**Respuesta:** La frase \"Qu√© rollo con el pollo\" es una expresi√≥n coloquial que denota sorpresa o confusi√≥n ante una situaci√≥n o comentario.', 'token_count': {'input_tokens': 501.0, 'output_tokens': 167.0}}, id='run--53ab2eb4-ecd3-4648-b84c-285ef5b6e72a-0', usage_metadata={'input_tokens': 501, 'output_tokens': 167, 'total_tokens': 668})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch(['Whats up buddy', 'Que pachuca por toluca', 'Que rollo con el pollo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75cdb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hey' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' there' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='!' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' Not' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' much' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' just' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' hanging' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' out' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' ready' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' chat' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' or' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' help' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' whatever' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='‚Äô' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='s' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' on' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' your' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' mind' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' How' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='‚Äô' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='s' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' it' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' going' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='?' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' Anything' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' exciting' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content=' happening' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='?' additional_kwargs={} response_metadata={} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n",
      "content='' additional_kwargs={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 38.0, 'input_tokens': 3.0, 'output_tokens': 35.0}} response_metadata={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 38.0, 'input_tokens': 3.0, 'output_tokens': 35.0}} id='run--c7b34eda-1d22-4f10-abb2-241dde815345'\n"
     ]
    }
   ],
   "source": [
    "for token in model.stream('Whats up buddy'):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6ec58",
   "metadata": {},
   "source": [
    "### Assembling LangChain objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f0d71",
   "metadata": {},
   "source": [
    "##### Imperative composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82db2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fe61456",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_frodo_b = ChatPromptTemplate.from_messages( \\\n",
    "[SystemMessage('Answer the question based on the context below. If the question \\\n",
    "cannot be answered, answer with \"Im sorry Mr. Frodo\".' ),\n",
    " HumanMessage('Context: {context}'),\n",
    " HumanMessage('Question: {question}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "477c1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@chain\n",
    "def chatbot(inputs_dict):\n",
    "    prompt = chat_template_frodo_b.invoke(inputs_dict)\n",
    "    answer = model.invoke(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d30b9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_chatbot = {'context': 'Tootland is a beautiful land home of the foos and the kunis' , \n",
    "                            'question': 'What is the capital of Tootland?'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "968afb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", additional_kwargs={'id': '7e84b3cb-22c1-434f-bdbe-e8d61d59f497', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, response_metadata={'id': '7e84b3cb-22c1-434f-bdbe-e8d61d59f497', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, id='run--4b51030a-ce6a-42b1-93df-c72192d3c251-0', usage_metadata={'input_tokens': 567, 'output_tokens': 24, 'total_tokens': 591})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(input_for_chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f802942",
   "metadata": {},
   "source": [
    "Using stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34f47c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def chatbot(inputs_dict):\n",
    "    prompt = chat_template_frodo_b.invoke(inputs_dict)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bde04c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=\"'m\" additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' sorry' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' Mr' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' Frodo' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' It' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' seems' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' there' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' no' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' context' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' provided' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' so' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' I' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' cannot' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' answer' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' your' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' question' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' If' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' provide' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' necessary' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' information' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' I' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=\"'ll\" additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' be' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' happy' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' assist' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n",
      "content='' additional_kwargs={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 72.0, 'input_tokens': 35.0, 'output_tokens': 37.0}} response_metadata={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 72.0, 'input_tokens': 35.0, 'output_tokens': 37.0}} id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1'\n"
     ]
    }
   ],
   "source": [
    "for part in chatbot.stream(input_for_chatbot):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4e56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', additional_kwargs={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 72.0, 'input_tokens': 35.0, 'output_tokens': 37.0}}, response_metadata={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 72.0, 'input_tokens': 35.0, 'output_tokens': 37.0}}, id='run--b59bc46f-a3d3-4d16-82f7-39e5ff0bcbb1')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part\n",
    "# each part is of type AIMessageChunk! not AIMessage!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df038848",
   "metadata": {},
   "source": [
    "Using async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2b67870",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "async def chatbot(inputs_dict):\n",
    "    prompt = await chat_template_frodo_b.ainvoke(inputs_dict)\n",
    "    answer = await model.ainvoke(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79f6c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer the question.\", additional_kwargs={'id': '338a063a-61ba-4538-ab50-4a64376b79e1', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer the question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, response_metadata={'id': '338a063a-61ba-4538-ab50-4a64376b79e1', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer the question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, id='run--88dbffdc-e950-4824-90c9-af55b7c1f661-0', usage_metadata={'input_tokens': 567, 'output_tokens': 24, 'total_tokens': 591})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatbot.ainvoke(input_for_chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0c3c1",
   "metadata": {},
   "source": [
    "##### Declarative composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_frodo_b = ChatPromptTemplate.from_messages( \\\n",
    "[SystemMessage('Answer the question based on the context below. If the question \\\n",
    "cannot be answered, answer with \"Im sorry Mr. Frodo\".' ),\n",
    " HumanMessage('Context: {context}'),\n",
    " HumanMessage('Question: {question}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0e69d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = chat_template_frodo_b | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a435579",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_chatbot = {'context': 'Tootland is a beautiful land home of the foos and the kunis' , \n",
    "                            'question': 'What is the capital of Tootland?'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38d0afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", additional_kwargs={'id': 'dea9a26a-1355-47a3-90b6-db2e17b3aed6', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, response_metadata={'id': 'dea9a26a-1355-47a3-90b6-db2e17b3aed6', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, id='run--48b0a66a-56ea-45f7-8c1b-b49945099b4a-0', usage_metadata={'input_tokens': 567, 'output_tokens': 24, 'total_tokens': 591})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(input_for_chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and you dont have to change the chatbot code for streaming or async! :D just how you ask the output to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac75e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=\"'m\" additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' sorry' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' Mr' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' Frodo' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' It' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' seems' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' there' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' no' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' context' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' provided' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' so' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' I' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' cannot' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' answer' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content=' question' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n",
      "content='' additional_kwargs={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 57.0, 'input_tokens': 35.0, 'output_tokens': 22.0}} response_metadata={'finish_reason': 'COMPLETE', 'token_count': {'total_tokens': 57.0, 'input_tokens': 35.0, 'output_tokens': 22.0}} id='run--f03c54ef-33cf-413e-a456-3aeaaeeed8bf'\n"
     ]
    }
   ],
   "source": [
    "# for streaming\n",
    "for part in chatbot.stream(input_for_chatbot):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79a238e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", additional_kwargs={'id': '51583cc2-e77f-458e-a824-a348a6902d3f', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, response_metadata={'id': '51583cc2-e77f-458e-a824-a348a6902d3f', 'finish_reason': 'COMPLETE', 'content': \"I'm sorry Mr. Frodo. It seems there is no context provided, so I cannot answer your question.\", 'token_count': {'input_tokens': 567.0, 'output_tokens': 24.0}}, id='run--012487c7-0091-4121-ba3d-26c84d2a4263-0', usage_metadata={'input_tokens': 567, 'output_tokens': 24, 'total_tokens': 591})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatbot.ainvoke(input_for_chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1885242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de4cf608",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-langchain-R4-LnOwj-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
